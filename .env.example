# Elideable Configuration
# Copy this file to .env and fill in your API keys

# Server Ports
PORT_ELIDE=8787
PORT_WEB=5173

# AI Provider Configuration
# Choose your preferred provider: anthropic, google, openrouter
ELV_PROVIDER=anthropic

# API Keys (add the ones you want to use)
# Anthropic (Recommended for best code generation)
ANTHROPIC_API_KEY=your_anthropic_key_here

# Google AI (Alternative)
GOOGLE_AI_API_KEY=your_google_key_here

# OpenRouter (Free models available)
OPENROUTER_API_KEY=your_openrouter_key_here

# Legacy OpenAI (if needed)
OPENAI_API_KEY=your_openai_key_here

# Optional: Database (Phase 2)
SUPABASE_URL=
SUPABASE_ANON_KEY=

# Optional: Sharing (Phase 2)
CLOUDFLARED_TOKEN=


# Local model via Elide + Ollama (set ELV_PROVIDER=local to use)
# OLLAMA_BASE_URL defaults to http://127.0.0.1:11434
# Recommended small model: gemma2:2b-instruct
OLLAMA_BASE_URL=
OLLAMA_MODEL=

